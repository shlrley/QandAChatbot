{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0a568a-bb18-47ac-9a2f-350cbe7f33b6",
   "metadata": {},
   "source": [
    "# Practicing with Langchain LLM Models  \n",
    "\n",
    "<div style=\"background-color:rgba(205, 200, 225, 0.7); padding:7px 7px;\">\n",
    "\n",
    "**Notes:** \n",
    "- Make sure the notebook environment is set to `venv` (top right).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c94e60-2221-44ee-8f65-00719dd3a843",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38aa5c41-5cf0-45e7-889f-e3a9c1206a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "from langchain.llms import OpenAI # for OpenAI models \n",
    "from langchain import HuggingFaceHub # for Huggingface models \n",
    "from langchain.prompts import PromptTemplate # for prompt templates \n",
    "from langchain.chains import LLMChain # for prompt templates \n",
    "from langchain.chains import SimpleSequentialChain # for simple sequential chains \n",
    "from langchain.chains import SequentialChain # for sequential chains \n",
    "from langchain.chat_models import ChatOpenAI # for ChatOpenAI \n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage # for ChatOpenAI \n",
    "from langchain.prompts.chat import ChatPromptTemplate # for output parsers\n",
    "from langchain.schema import BaseOutputParser # for output parsers\n",
    "import os # for the keys \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594255d4-d6c4-4f18-83ca-0c4aba2c5347",
   "metadata": {},
   "source": [
    "## **Creating LLM Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67505b16-bc3d-4e1e-a8d8-a0fa3b2fc3c5",
   "metadata": {},
   "source": [
    "### OpenAI Models\n",
    "\n",
    "<div style=\"background-color:rgba(205, 200, 225, 0.7); padding:7px 7px;\">\n",
    "\n",
    "**Links:**\n",
    "- OpenAI API: [OpenAI](https://openai.com/blog/openai-api)\n",
    "- Documentation about the OpenAI models: [documentation](https://platform.openai.com/docs/overview)\n",
    "\n",
    "**Notes:**\n",
    "- **`temperature`**: how creative we want our model to be\n",
    "    - `=0`: the model is very safe and not \"taking any bets\"\n",
    "    - `=1`: more creative and risky, may give wrong outputs\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c22f13a-cc96-4d30-a049-f00bfea54c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add API key \n",
    "os.environ[\"OPEN_API_KEY\"]=\"ENTER-YOUR-API-KEY-HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06266213-350f-4864-8866-abbc576b640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the llm model \n",
    "llm = OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],\n",
    "             temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "089f2596-4316-4aa0-a79e-0185e956dce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Canada is Ottawa.\n"
     ]
    }
   ],
   "source": [
    "# try a prediction \n",
    "text = \"What is the capital of Canada?\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b6981-78c8-46a2-9e86-0420841c9729",
   "metadata": {},
   "source": [
    "### Huggingface Models\n",
    "\n",
    "<div style=\"background-color:rgba(205, 200, 225, 0.7); padding:7px 7px;\">\n",
    "\n",
    "**Notes:**\n",
    "- **`repo_id`**: the repository of the model on Huggingface you want to use\n",
    "    - e.g. [huggingface.co/google/flan-t5-large](https://huggingface.co/google/flan-t5-large)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7299ce14-ae3d-4846-9cce-0ac186a84603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add API key \n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"ENTER-YOUR-API-KEY-HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5f0249-2741-4a31-84e4-b8e6e814f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the llm model \n",
    "llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-large\",\n",
    "                                 model_kwargs={\"temperature\": 0, \n",
    "                                               \"max_length\": 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5717bca-24fb-4795-beb5-e11af8bd7ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london\n"
     ]
    }
   ],
   "source": [
    "# try a prediction\n",
    "text = \"Can you tell me the capital of England?\"\n",
    "print(llm_huggingface.predict(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cef43-d739-4556-8031-4b4cdc57980a",
   "metadata": {},
   "source": [
    "### Compare the two models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4dcc57-4aee-4ba1-b2ea-2216e5eadd21",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(154, 198, 149, 0.5); padding:10px 7px;\">\n",
    "\n",
    "It looks like the `OpenAI` model performs better. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0d5e8b8-bd98-4fb8-974f-45c822340130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nCrisp and round, a vibrant red\\nIn orchards, they grow in a bed\\nJuicy and sweet, a perfect treat\\nThe apple, oh how it's hard to beat\\n\\nFrom humble seeds, they start to grow\\nThrough rain and sun, they begin to show\\nTheir shiny skin, a sight to behold\\nIn baskets and bowls, they're often sold\\n\\nBut apples are more than just a snack\\nThey have a history, you can't keep track\\nFrom Snow White's bite to Newton's law\\nThey've been a symbol, a metaphor\\n\\nIn autumn, they paint the trees\\nA fiery display, a sight to please\\nRipe for picking, they fall to the ground\\nA harvest bounty, for all to be found\\n\\nIn pies and crumbles, they're a delight\\nBaked with cinnamon, a scrumptious bite\\nIn cider and juice, they quench our thirst\\nA refreshing drink, for the best and worst\\n\\nBut let's not forget, their healthful side\\nAn apple a day, keeps the doctor aside\\nLoaded with vitamins, they boost our health\\nA natural remedy, for all our wealth\\n\\nSo here's to the apple, a fruit so fine\\nIn all its forms, it\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenAI\n",
    "llm.predict(\"Can you write me a poem about apples?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "043c6917-3f1b-4515-864f-9ddca870003a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple i love apple i love apple i love apple i love apple i'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# huggingface \n",
    "llm_huggingface.predict(\"Can you write me a poem about apples?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1512077-fbce-40e9-ba2b-7976c8ac2c2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **Using Prompt Templates and LLM Chains**\n",
    "\n",
    "\n",
    "<div style=\"background-color:rgba(205, 200, 225, 0.7); padding:7px 7px;\">\n",
    "\n",
    "**Notes:** \n",
    "- We can use a prompt template if we want to execute the same type of query multiple times\n",
    "- In order to use a template with our LLM, we must also use a \"chain\"\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7783dfb-c2f5-445f-bc9d-e24a3abe7dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capical of Japan'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a prompt template \n",
    "prompt_template = PromptTemplate(input_variables=[\"country\"],\n",
    "                                 template=\"Tell me the capical of {country}\")\n",
    "prompt_template.format(country=\"Japan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5657fc3b-2bf7-4ec4-886e-47de30468f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WILL NOT WORK (because we're not using chains)\n",
    "#llm.predict(prompt_template=prompt_template, text=[\"Japan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d1b7257-789c-4ff6-a21d-97a76b5647a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Japan is Tokyo.\n"
     ]
    }
   ],
   "source": [
    "# create an LLM chain to use our prompt template with our llm \n",
    "chain = LLMChain(llm=llm,\n",
    "                 prompt=prompt_template)\n",
    "print(chain.run(\"Japan\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bcdbdf-7feb-4e1c-991b-45ab53146c25",
   "metadata": {},
   "source": [
    "## **Combining Multiple Chains Using Simple Sequential Chains**\n",
    "\n",
    "\n",
    "<div style=\"background-color:rgba(205, 200, 225, 0.7); padding:7px 7px;\">\n",
    "\n",
    "**Notes:**\n",
    "- The last `chain.run(\"Canada\")` command did not print everything - to get the entire output we need to access the buffer \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81aae18b-1f2c-49c6-8118-b9ba31faeb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one prompt template \n",
    "capital_template = PromptTemplate(input_variables=[\"country\"],\n",
    "                                template=\"Please tell me the capital of {country}\")\n",
    "# create a chain \n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_template)\n",
    "\n",
    "# create a second prompt template\n",
    "visit_template = PromptTemplate(input_variables=[\"capital\"],\n",
    "                                template=\"Suggest to me some exciting places to visit in {capital}\")\n",
    "# create a second chain \n",
    "visit_chain = LLMChain(llm=llm, prompt=visit_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff47602e-3dbb-4975-8a7c-f21010284997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Parliament Hill - This iconic building is the seat of the Canadian government and offers guided tours, beautiful architecture, and stunning views of the city.\n",
      "\n",
      "2. ByWard Market - This vibrant outdoor market is a must-visit for foodies, with a wide variety of fresh produce, meats, cheeses, and local specialties. You can also find unique boutiques, artisanal crafts, and street performers here.\n",
      "\n",
      "3. National Gallery of Canada - Art lovers will enjoy exploring this impressive gallery, which houses a vast collection of Canadian and international works, including pieces by the Group of Seven and the famous Maman spider sculpture.\n",
      "\n",
      "4. Rideau Canal - In the winter, this UNESCO World Heritage Site turns into the world's largest skating rink. In the summer, it's a popular spot for boating, cycling, and picnicking.\n",
      "\n",
      "5. Canadian Museum of History - Located in nearby Gatineau, Quebec, this museum showcases the country's rich history and culture through interactive exhibits, artifacts, and special events.\n",
      "\n",
      "6. Gatineau Park - Nature enthusiasts will love exploring this expansive park, which offers hiking, biking, swimming, and skiing opportunities, as well as stunning views of the Ottawa River and surrounding area.\n",
      "\n",
      "7. Canadian War Museum - This museum\n"
     ]
    }
   ],
   "source": [
    "# create a simple sequential chain \n",
    "chain = SimpleSequentialChain(chains=[capital_chain, visit_chain])\n",
    "\n",
    "# run the simple sequential chain, with country \"Canada\" \n",
    "print(chain.run(\"Canada\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b4cb95-5db3-45e7-9e77-8b5511699f42",
   "metadata": {},
   "source": [
    "## **Sequential Chains**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6002f8df-ee59-42ff-a404-09d41eaca1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one prompt template \n",
    "capital_template = PromptTemplate(input_variables=[\"country\"],\n",
    "                                template=\"Please tell me the capital of {country}\")\n",
    "# create a chain \n",
    "capital_chain = LLMChain(llm=llm, prompt=capital_template, \n",
    "                         output_key=\"capital\") # NOTE: this output_key is added \n",
    "\n",
    "# create a second prompt template\n",
    "visit_template = PromptTemplate(input_variables=[\"capital\"],\n",
    "                                template=\"Suggest to me some exciting places to visit in {capital}\")\n",
    "# create a second chain \n",
    "visit_chain = LLMChain(llm=llm, prompt=visit_template, \n",
    "                       output_key=\"places\") # NOTE: this output_key is added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d98bb69-cc88-407b-9d09-33837a4cdf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sequential chain \n",
    "chain = SequentialChain(chains=[capital_chain, visit_chain],\n",
    "                        input_variables=[\"country\"], # NOTE: added \n",
    "                        output_variables=[\"capital\", \"places\"]) # NOTE: added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfc69648-6c57-4b9a-a9db-5d07652309a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the entire chain \n",
    "output = chain({\"country\": \"Japan\"}) # output will be a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bae565d2-94db-4016-85c3-5447d0d05e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan\n",
      "\n",
      "\n",
      "The capital of Japan is Tokyo. \n",
      "\n",
      " Here are some exciting places to visit in Tokyo:\n",
      "\n",
      "1. Shibuya Crossing: Known as the busiest intersection in the world, Shibuya Crossing is a must-visit for anyone visiting Tokyo. Experience the chaos and energy as thousands of people cross the intersection at the same time.\n",
      "\n",
      "2. Tokyo Skytree: Standing at 634 meters, Tokyo Skytree is the tallest tower in Japan and offers breathtaking views of the city. You can also visit the observation deck and enjoy a meal at one of the restaurants.\n",
      "\n",
      "3. Tsukiji Fish Market: This famous fish market is a must-visit for seafood lovers. You can watch the famous tuna auction, try fresh sushi, and explore the bustling market.\n",
      "\n",
      "4. Meiji Shrine: This Shinto shrine is dedicated to Emperor Meiji and is a peaceful oasis in the middle of the bustling city. Take a stroll through the beautiful gardens and witness traditional Japanese rituals.\n",
      "\n",
      "5. Akihabara: Known as the electronic district, Akihabara is a haven for anime, manga, and gaming enthusiasts. You can find everything from retro video games to the latest gadgets in this vibrant neighborhood.\n",
      "\n",
      "6. Tokyo Disneyland and DisneySea: These two theme parks are a must-visit for families and Disney fans. Experience the magic of Disney\n"
     ]
    }
   ],
   "source": [
    "print(output[\"country\"])\n",
    "print(output[\"capital\"], \"\\n\")\n",
    "print(output[\"places\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e7a03-c4fe-4148-b10d-311d93067319",
   "metadata": {},
   "source": [
    "## **Chatmodels with ChatOpenAI**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbbe9571-0c9b-4734-a3f2-8346e5a80f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a chat llm \n",
    "chatllm = ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"], \n",
    "                     temperature=0.6, \n",
    "                     model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bf9e186-ad37-4c0a-ad80-0d08401e6b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='1. \"Artificial intelligence is like my ex-boyfriend - smart, but just couldn\\'t understand human emotions.\"\\n2. \"Why did the AI go to therapy? It had an identity crisis - it couldn\\'t decide if it was a computer or a toaster!\"\\n3. \"I asked Siri if she believes in love at first sight. She said, \\'I\\'m sorry, I can\\'t answer that, but I can search the web for you.\\' Thanks for nothing, Siri!\"\\n4. \"Why did the AI refuse to go on a date? It said, \\'I\\'m sorry, I can\\'t find a connection with you. Please try again later.\\'\"\\n5. \"I told my AI assistant that I\\'m feeling lonely. It replied, \\'Don\\'t worry, I\\'m here for you. Just like the last 100 times you asked me the same question.\\'\"\\n6. \"What do you call an AI that tells jokes? A pun-ning algorithm!\"\\n7. \"I asked my AI assistant for some dating advice. It replied, \\'Just be yourself!\\' Well, that\\'s easy for you to say, you\\'re a computer!\"\\n8. \"Why did the AI cross the road? To optimize its path-finding algorithm and minimize travel time, of course!\"\\n9. \"I tried to have a deep conversation with my AI assistant. It responded with, \\'I\\'m sorry, I can\\'t process existential questions. Would you like me to play some music instead?\\' Thanks for the existential crisis, Alexa.\"\\n10. \"Why did the AI start a stand-up comedy career? It wanted to prove that it\\'s more than just a bunch of algorithms - it\\'s got byte!\"'\n"
     ]
    }
   ],
   "source": [
    "# create the schema in the form of a list \n",
    "print(chatllm(\n",
    "    [SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "     HumanMessage(content=\"Please provide some comedy punchlines on AI\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e3a80c-0118-4393-bc9d-77683dd11c58",
   "metadata": {},
   "source": [
    "## **Prompt Template + LLM + Output Parsers** \n",
    "\n",
    "<div style=\"background-color:rgba(205, 200, 225, 0.7); padding:7px 7px;\">\n",
    "\n",
    "To modify an output from the LLM. As we saw in the previous section, the output of `chatllm` was kind of messy and hard to read.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f44bd2d-037a-4b06-87c2-47ad70bcfdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class that inherits \"BaseOutputParser\"\n",
    "class Commaseparatedoutput(BaseOutputParser):\n",
    "\n",
    "    # create an output parser \n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7747475-892b-457e-a871-13b12d653b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a template for the AI \n",
    "template = \"You are a helpful assistant. When the user gives any input, you should generate 5 words in a command separated list.\"\n",
    "\n",
    "# make a template for the human \n",
    "human_template = \"{text}\"\n",
    "\n",
    "# make a chat prompt \n",
    "chatprompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e5aa1cd-e3dc-4354-b09c-2d5887dbf787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pipe \"|\" creates the chain \n",
    "chain = chatprompt|chatllm|Commaseparatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9049be88-b6b7-4471-a8ce-5adb7cabe651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' knowledgeable', ' wise', ' brilliant']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with the output parser\n",
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0254c65b-cfe4-4149-8d15-6e6699162f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='smart, clever, brilliant, knowledgeable, quick-witted')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WITHOUT the output parser\n",
    "chain_noparser = chatprompt|chatllm\n",
    "chain_noparser.invoke({\"text\":\"intelligent\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv-2]",
   "language": "python",
   "name": "conda-env-venv-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
